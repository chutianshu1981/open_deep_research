# Open Deep Research 模型配置详细指南

## 🎯 四种模型的作用分工

### 1. 总结模型 (Summarization Model)
**用途**：总结搜索 API 返回的原始结果
**工作流程**：搜索结果 → 总结模型 → 结构化摘要
**特点**：
- 处理大量搜索结果文本
- 需要快速响应
- 输出相对简单
- 调用频率高

**推荐配置**：
```bash
SUMMARIZATION_MODEL=openai:gpt-4o-mini        # 成本优化
SUMMARIZATION_MODEL_MAX_TOKENS=8192          # 足够处理摘要
```

### 2. 研究模型 (Research Model)
**用途**：执行主要的研究和分析任务
**工作流程**：研究问题 → 研究模型 → 深度分析和工具调用
**特点**：
- 需要强大的推理能力
- 负责工具调用和搜索
- 处理复杂的研究逻辑
- 质量要求最高

**推荐配置**：
```bash
RESEARCH_MODEL=openai:gpt-4o                  # 质量优先
RESEARCH_MODEL_MAX_TOKENS=10000              # 支持复杂输出
```

### 3. 压缩模型 (Compression Model)
**用途**：压缩多个研究单元的结果
**工作流程**：多个研究结果 → 压缩模型 → 精炼的研究发现
**特点**：
- 处理多个并发研究的结果
- 需要良好的信息整合能力
- 平衡详细度和简洁性
- 中等复杂度任务

**推荐配置**：
```bash
COMPRESSION_MODEL=openai:gpt-4o-mini          # 成本与质量平衡
COMPRESSION_MODEL_MAX_TOKENS=8192            # 适中的输出长度
```

### 4. 最终报告模型 (Final Report Model)
**用途**：生成最终的综合研究报告
**工作流程**：所有研究发现 → 最终报告模型 → 完整报告
**特点**：
- 需要优秀的写作能力
- 整合所有研究成果
- 生成结构化的长文档
- 代表系统的最终输出质量

**推荐配置**：
```bash
FINAL_REPORT_MODEL=openai:gpt-4o              # 质量优先
FINAL_REPORT_MODEL_MAX_TOKENS=10000          # 支持长报告
```

## 🔧 不同场景的配置策略

### 场景一：质量优先（不考虑成本）
```bash
# 全部使用最强模型
SUMMARIZATION_MODEL=openai:gpt-4o
RESEARCH_MODEL=openai:gpt-4o
COMPRESSION_MODEL=openai:gpt-4o
FINAL_REPORT_MODEL=openai:gpt-4o
```

### 场景二：成本优化（预算有限）
```bash
# 关键任务用强模型，其他用便宜模型
SUMMARIZATION_MODEL=openai:gpt-4o-mini
RESEARCH_MODEL=openai:gpt-4o-mini
COMPRESSION_MODEL=openai:gpt-4o-mini
FINAL_REPORT_MODEL=openai:gpt-4o              # 只有最终报告用强模型
```

### 场景三：平衡配置（推荐）
```bash
# 根据任务重要性分配模型
SUMMARIZATION_MODEL=openai:gpt-4o-mini        # 简单任务用便宜模型
RESEARCH_MODEL=openai:gpt-4o                  # 核心任务用强模型
COMPRESSION_MODEL=openai:gpt-4o-mini          # 中等任务用中等模型
FINAL_REPORT_MODEL=openai:gpt-4o              # 最终输出用强模型
```

### 场景四：多提供商配置
```bash
# 利用不同提供商的优势
SUMMARIZATION_MODEL=openai:gpt-4o-mini        # OpenAI 的快速模型
RESEARCH_MODEL=anthropic:claude-3-5-sonnet    # Anthropic 的推理能力
COMPRESSION_MODEL=openai:gpt-4o-mini          # OpenAI 的成本效益
FINAL_REPORT_MODEL=anthropic:claude-3-5-sonnet # Anthropic 的写作能力
```

### 场景五：本地部署
```bash
# 使用本地 Ollama 模型
SUMMARIZATION_MODEL=ollama:llama3:8b
RESEARCH_MODEL=ollama:llama3:70b              # 使用更大的模型做研究
COMPRESSION_MODEL=ollama:llama3:8b
FINAL_REPORT_MODEL=ollama:llama3:70b
```

## 🌐 支持的模型提供商和格式

### OpenAI 系列
```bash
openai:gpt-4o                    # 最新最强模型
openai:gpt-4o-mini               # 成本优化模型
openai:gpt-4-turbo               # 高性能模型
openai:gpt-3.5-turbo             # 经济型模型
```

### Anthropic 系列
```bash
anthropic:claude-3-5-sonnet      # 最新 Claude 模型
anthropic:claude-3-opus          # 最强推理能力
anthropic:claude-3-sonnet        # 平衡性能
anthropic:claude-3-haiku         # 快速响应
```

### Google 系列
```bash
google:gemini-1.5-pro            # Google 最强模型
google:gemini-1.5-flash          # 快速模型
google:gemini-pro                # 标准模型
```

### 其他提供商
```bash
groq:llama3-70b-8192             # Groq 超快推理
groq:mixtral-8x7b-32768          # Mixtral 模型
deepseek:deepseek-chat           # DeepSeek 模型
ollama:llama3                    # 本地 Llama
ollama:mistral                   # 本地 Mistral
```

### OpenRouter 聚合服务
```bash
openrouter:anthropic/claude-3.5-sonnet
openrouter:openai/gpt-4o
openrouter:meta-llama/llama-3-70b-instruct
openrouter:mistralai/mixtral-8x7b-instruct
```

## ⚙️ Token 配置建议

### 根据任务复杂度调整
```bash
# 简单任务
SUMMARIZATION_MODEL_MAX_TOKENS=4096

# 中等任务  
COMPRESSION_MODEL_MAX_TOKENS=8192

# 复杂任务
RESEARCH_MODEL_MAX_TOKENS=16384
FINAL_REPORT_MODEL_MAX_TOKENS=16384
```

### 根据模型能力调整
```bash
# 强模型可以处理更长输出
RESEARCH_MODEL=openai:gpt-4o
RESEARCH_MODEL_MAX_TOKENS=16384

# 弱模型限制输出长度
SUMMARIZATION_MODEL=openai:gpt-4o-mini
SUMMARIZATION_MODEL_MAX_TOKENS=4096
```

## 🔍 搜索 API 兼容性

### Tavily（推荐）
- ✅ 兼容所有模型
- ✅ 专为 AI 优化
- ✅ 结果质量高

### OpenAI 原生搜索
- ⚠️ 仅支持 OpenAI 模型
- ✅ 集成度高
- ⚠️ 可能有使用限制

### Anthropic 原生搜索
- ⚠️ 仅支持 Anthropic 模型
- ✅ 集成度高
- ⚠️ 功能相对有限

## 🚀 快速配置模板

### 复制以下配置到你的 .env 文件：

**高质量配置**：
```bash
SUMMARIZATION_MODEL=openai:gpt-4o-mini
RESEARCH_MODEL=anthropic:claude-3-5-sonnet
COMPRESSION_MODEL=openai:gpt-4o-mini
FINAL_REPORT_MODEL=anthropic:claude-3-5-sonnet
SEARCH_API=tavily
```

**经济型配置**：
```bash
SUMMARIZATION_MODEL=openai:gpt-4o-mini
RESEARCH_MODEL=openai:gpt-4o-mini
COMPRESSION_MODEL=openai:gpt-4o-mini
FINAL_REPORT_MODEL=openai:gpt-4o
SEARCH_API=tavily
```

**本地配置**：
```bash
SUMMARIZATION_MODEL=ollama:llama3:8b
RESEARCH_MODEL=ollama:llama3:70b
COMPRESSION_MODEL=ollama:llama3:8b
FINAL_REPORT_MODEL=ollama:llama3:70b
SEARCH_API=tavily
```

根据你的需求选择合适的配置，然后在 .env 文件中设置相应的 API 密钥即可！
