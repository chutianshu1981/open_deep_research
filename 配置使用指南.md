# 详细配置使用指南

## 🎯 配置完成情况

✅ **已完成**：我已经为你创建了一个详细的 `.env` 配置文件，包含：

### 📋 配置项目清单

#### 1. API 密钥配置
- ✅ `OPENAI_API_KEY` - OpenAI 服务
- ✅ `ANTHROPIC_API_KEY` - Anthropic 服务  
- ✅ `GOOGLE_API_KEY` - Google/Vertex AI 服务
- ✅ `GROQ_API_KEY` - Groq 服务
- ✅ `DEEPSEEK_API_KEY` - DeepSeek 服务
- ✅ `TAVILY_API_KEY` - Tavily 搜索服务

#### 2. 通用配置
- ✅ `MAX_STRUCTURED_OUTPUT_RETRIES=3` - 结构化输出重试次数
- ✅ `ALLOW_CLARIFICATION=true` - 是否允许澄清问题
- ✅ `MAX_CONCURRENT_RESEARCH_UNITS=5` - 最大并发研究单元

#### 3. 研究配置
- ✅ `SEARCH_API=tavily` - 搜索 API 选择
- ✅ `MAX_RESEARCHER_ITERATIONS=3` - 研究监督者迭代次数
- ✅ `MAX_REACT_TOOL_CALLS=5` - 工具调用次数限制

#### 4. 四种模型配置
- ✅ `SUMMARIZATION_MODEL=openai:gpt-4o-mini` - 总结模型
- ✅ `RESEARCH_MODEL=openai:gpt-4o` - 研究模型
- ✅ `COMPRESSION_MODEL=openai:gpt-4o-mini` - 压缩模型
- ✅ `FINAL_REPORT_MODEL=openai:gpt-4o` - 最终报告模型

#### 5. Token 限制配置
- ✅ 每个模型都有对应的 `MAX_TOKENS` 配置
- ✅ 根据任务复杂度设置了合理的默认值

## 🔧 下一步操作

### 1. 填入你的 API 密钥

根据你要使用的服务，填入相应的 API 密钥：

```bash
# 必需的（至少需要一个模型提供商）
OPENAI_API_KEY=sk-your-openai-key-here

# 推荐的（用于搜索）
TAVILY_API_KEY=tvly-your-tavily-key-here

# 可选的（根据你选择的模型）
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
GOOGLE_API_KEY=your-google-key-here
```

### 2. 自定义模型配置

根据你的需求修改模型配置：

#### 示例 1：全部使用 OpenAI
```bash
SUMMARIZATION_MODEL=openai:gpt-4o-mini
RESEARCH_MODEL=openai:gpt-4o
COMPRESSION_MODEL=openai:gpt-4o-mini
FINAL_REPORT_MODEL=openai:gpt-4o
```

#### 示例 2：混合使用多个提供商
```bash
SUMMARIZATION_MODEL=openai:gpt-4o-mini
RESEARCH_MODEL=anthropic:claude-3-5-sonnet
COMPRESSION_MODEL=openai:gpt-4o-mini
FINAL_REPORT_MODEL=anthropic:claude-3-5-sonnet
```

#### 示例 3：使用 OpenRouter 聚合服务
```bash
SUMMARIZATION_MODEL=openrouter:openai/gpt-4o-mini
RESEARCH_MODEL=openrouter:anthropic/claude-3.5-sonnet
COMPRESSION_MODEL=openrouter:openai/gpt-4o-mini
FINAL_REPORT_MODEL=openrouter:anthropic/claude-3.5-sonnet
```

### 3. 调整性能参数

根据你的硬件和网络条件调整：

```bash
# 如果网络较慢或API有限制，减少并发
MAX_CONCURRENT_RESEARCH_UNITS=3

# 如果需要更深入的研究，增加迭代次数
MAX_RESEARCHER_ITERATIONS=5

# 如果模型经常解析失败，增加重试次数
MAX_STRUCTURED_OUTPUT_RETRIES=5
```

## 🚀 启动测试

配置完成后，启动服务进行测试：

```bash
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev --allow-blocking
```

## 🔍 配置验证

### 检查配置是否生效

1. **启动服务后**，在 LangGraph Studio 中查看配置面板
2. **确认模型配置**：检查是否显示了你设置的模型
3. **测试功能**：提交一个简单的研究问题
4. **查看日志**：观察是否使用了正确的模型

### 常见问题排查

#### 问题 1：模型不支持结构化输出
**症状**：出现解析错误
**解决**：确保使用支持结构化输出的模型版本

#### 问题 2：API 密钥无效
**症状**：认证失败错误
**解决**：检查 API 密钥是否正确，是否有足够配额

#### 问题 3：搜索功能不工作
**症状**：无法获取搜索结果
**解决**：检查 `TAVILY_API_KEY` 是否配置正确

#### 问题 4：并发限制错误
**症状**：速率限制错误
**解决**：减少 `MAX_CONCURRENT_RESEARCH_UNITS` 的值

## 📊 性能优化建议

### 成本优化
```bash
# 使用更便宜的模型处理简单任务
SUMMARIZATION_MODEL=openai:gpt-4o-mini
COMPRESSION_MODEL=openai:gpt-4o-mini

# 只在关键任务使用强模型
RESEARCH_MODEL=openai:gpt-4o
FINAL_REPORT_MODEL=openai:gpt-4o
```

### 速度优化
```bash
# 使用快速模型
SUMMARIZATION_MODEL=groq:llama3-8b-8192
RESEARCH_MODEL=groq:llama3-70b-8192

# 增加并发
MAX_CONCURRENT_RESEARCH_UNITS=8
```

### 质量优化
```bash
# 使用最强模型
RESEARCH_MODEL=anthropic:claude-3-5-sonnet
FINAL_REPORT_MODEL=anthropic:claude-3-5-sonnet

# 增加迭代次数
MAX_RESEARCHER_ITERATIONS=5
```

## 🎯 推荐配置方案

### 方案 A：高质量研究（推荐）
```bash
OPENAI_API_KEY=your-key
ANTHROPIC_API_KEY=your-key
TAVILY_API_KEY=your-key

SUMMARIZATION_MODEL=openai:gpt-4o-mini
RESEARCH_MODEL=anthropic:claude-3-5-sonnet
COMPRESSION_MODEL=openai:gpt-4o-mini
FINAL_REPORT_MODEL=anthropic:claude-3-5-sonnet
SEARCH_API=tavily
```

### 方案 B：成本优化
```bash
OPENAI_API_KEY=your-key
TAVILY_API_KEY=your-key

SUMMARIZATION_MODEL=openai:gpt-4o-mini
RESEARCH_MODEL=openai:gpt-4o-mini
COMPRESSION_MODEL=openai:gpt-4o-mini
FINAL_REPORT_MODEL=openai:gpt-4o
SEARCH_API=tavily
```

### 方案 C：本地部署
```bash
TAVILY_API_KEY=your-key

SUMMARIZATION_MODEL=ollama:llama3:8b
RESEARCH_MODEL=ollama:llama3:70b
COMPRESSION_MODEL=ollama:llama3:8b
FINAL_REPORT_MODEL=ollama:llama3:70b
SEARCH_API=tavily
```

现在你可以根据自己的需求选择合适的配置方案，填入相应的 API 密钥，然后启动服务进行测试！
